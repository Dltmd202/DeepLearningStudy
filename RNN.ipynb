{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwUm9DJScCvwQ+JuO72KSE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dltmd202/DeepLearningStudy/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDILt5_Hd4Hy",
        "outputId": "38b0cd2a-2e32-4eb1-ffeb-1fb56a61154d"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "np.random.seed(42)\n",
        "\n",
        "(x_train_all, y_train_all), (x_test, y_test) = imdb.load_data(skip_top=20, num_words=100)\n",
        "word_to_index = imdb.get_word_index()\n",
        "\n",
        "for i in range(len(x_train_all)):\n",
        "  x_train_all[i] = [w for w in x_train_all[i] if w > 2]\n",
        "\n",
        "random_index = np.random.permutation(25000)\n",
        "x_train = x_train_all[random_index[:20000]]\n",
        "y_train = y_train_all[random_index[:20000]]\n",
        "x_val = x_train_all[random_index[20000:]]\n",
        "y_val = y_train_all[random_index[20000:]]\n",
        "\n",
        "maxlen=100\n",
        "x_train_seq = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val_seq = sequence.pad_sequences(x_val, maxlen=maxlen)\n",
        "\n",
        "x_train_onehot = to_categorical(x_train_seq)\n",
        "x_val_onehot = to_categorical(x_val_seq)\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "sqfoLRSOqTyK",
        "outputId": "0bcb2e25-76e8-45ce-a476-d0d985da9039"
      },
      "source": [
        "class RecurrentNetwork:\n",
        "  def __init__(self, n_cell=10, batch_size=32, learning_rate=0.1):\n",
        "    self.n_cells = n_cells\n",
        "    self.batch_size = batch_size\n",
        "    self.w1h = None\n",
        "    self.w1x = None\n",
        "    self.b1 = None\n",
        "    self.w2 = None\n",
        "    self.b2 = None\n",
        "    self.h = None\n",
        "    self.losses = []\n",
        "    self.val_losses = []\n",
        "    self.lr = learning_rate\n",
        "  \n",
        "  def forpass(self, x):\n",
        "    self.h = [np.zeros((x.shape[0], self.n_cells))]\n",
        "\n",
        "    seq = np.swapaxes(x, 0, 1)\n",
        "    for x in seq:\n",
        "      z1 = np.dot(x, self.w1x) + np.dot(self.h[-1], self.w1h) + self.b1\n",
        "      h = np.tanh(z1)\n",
        "      self.h.append(h)\n",
        "      z2 = np.dot(h, self.w2) + self.b2\n",
        "    return z2\n",
        "  \n",
        "  def backprop(self, x, err):\n",
        "    m = len(x)\n",
        "\n",
        "    w2_grad = np.dot(self.h[-1].T, err) / m\n",
        "    b2_grad = np.sum(err) / m\n",
        "    seq = np.swapaxes(x, 0, 1)\n",
        "    w1h_grad = w1x_grad = b1_grad = 0\n",
        "    err_to_cell = np.dot(err, self.w2.T) * (1 - self.h[-1] ** 2)\n",
        "    for x, h in zip(seq[::-1][:10], self.h[:-1][::-1][:10]):\n",
        "      w1h_grad += np.dot(h.T, err_to_cell)\n",
        "      w1x_grad += np.dot(x.T, err_to_cell)\n",
        "      b1_grad += np.sum(err_to_cell, axis=0)\n",
        "      err_to_cell = np.dot(err_to_cell, self.w1h) * (1 - h ** 2)\n",
        "    \n",
        "    w1h_grad /= m\n",
        "    w1x_grad /= m\n",
        "    b1_grad /= m\n",
        "\n",
        "    return w1h_grad, w1x_grad, b1_grad, w1_grad, b2_grad\n",
        "  \n",
        "  def sigmoid(self, z):\n",
        "    a = 1 /(1 + np.exp(-z))\n",
        "    return a\n",
        "  \n",
        "  def init_weights(self, n_features, n_classes):\n",
        "    orth_init = tf.initializers.Orthogonal()\n",
        "    glorot_init = tf.initializers.GlorotUniform()\n",
        "\n",
        "    self.w1h = orth_init((self.n_cells, self.n_cell)).numpy()\n",
        "    self.w1x = glorot_init((n_features, self.n_cell)).numpy()\n",
        "    self.b1 = np.zeros(self.n_cells)\n",
        "    self.w2 = glorot_init((self.n_cells, n_classes)).numpy()\n",
        "    self.b2 = np.zeros(n_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-3cdbb11bf397>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    self.h = [np.zeros((x.shape[0], self.n_cells)))]\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT-5zf0Ruy1c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}